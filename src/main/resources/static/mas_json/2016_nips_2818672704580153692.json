{"title": "Recovery Guarantee of Non-negative Matrix Factorization via Alternating Updates.", "fields": ["matrix decomposition", "non negative matrix factorization", "linear independence", "exploit", "generative model"], "abstract": "Non-negative matrix factorization is a popular tool for decomposing data into feature and weight matrices under non-negativity constraints. It enjoys practical success but is poorly understood theoretically. This paper proposes an algorithm that alternates between decoding the weights and updating the features, and shows that assuming a generative model of the data, it provably recovers the ground-truth under fairly mild conditions. In particular, its only essential requirement on features is linear independence. Furthermore, the algorithm uses ReLU to exploit the non-negativity for decoding the weights, and thus can tolerate adversarial noise that can potentially be as large as the signal, and can tolerate unbiased noise much larger than the signal. The analysis relies on a carefully designed coupling between two potential functions, which we believe is of independent interest.", "citation": "Citations (3)", "departments": ["Princeton University", "Princeton University", "Princeton University"], "authors": ["Yuanzhi Li.....http://dblp.org/pers/hd/l/Li:Yuanzhi", "Yingyu Liang.....http://dblp.org/pers/hd/l/Liang:Yingyu", "Andrej Risteski.....http://dblp.org/pers/hd/r/Risteski:Andrej"], "conf": "nips", "year": "2016", "pages": 9}
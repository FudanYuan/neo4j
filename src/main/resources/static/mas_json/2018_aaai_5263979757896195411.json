{"title": "RelNN: A Deep Neural Model for Relational Learning.", "fields": ["scalability", "deep learning", "property", "statistical relational learning", "modular design"], "abstract": "Statistical relational AI (StarAI) aims at reasoning and learning in noisy domains described in terms of objects and relationships by combining probability with first-order logic. With huge advances in deep learning in the current years, combining deep networks with first-order logic has been the focus of several recent studies. Many of the existing attempts, however, only focus on relations and ignore object properties. The attempts that do consider object properties are limited in terms of modelling power or scalability. In this paper, we develop relational neural networks (RelNNs) by adding hidden layers to relational logistic regression (the relational counterpart of logistic regression). We learn latent properties for objects both directly and through general rules. Back-propagation is used for training these models. A modular, layer-wise architecture facilitates utilizing the techniques developed within deep learning community to our architecture. Initial experiments on eight tasks over three real-world datasets show that RelNNs are promising models for relational learning.", "citation": "Citations (2)", "departments": ["University of British Columbia", "University of British Columbia"], "authors": ["Seyed Mehran Kazemi.....http://dblp.org/pers/hd/k/Kazemi:Seyed_Mehran", "David Poole.....http://dblp.org/pers/hd/p/Poole_0001:David"], "conf": "aaai", "year": "2018", "pages": 9}
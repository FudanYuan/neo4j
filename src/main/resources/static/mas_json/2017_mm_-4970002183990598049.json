{"title": "Deep Binary Reconstruction for Cross-modal Hashing.", "fields": ["dynamic perfect hashing", "pattern recognition", "hash function", "universal hashing", "computer vision", "modal", "binary number", "activation function", "k independent hashing", "binary constraint"], "abstract": "With the increasing demand of massive multimodal data storage and organization, cross-modal retrieval based on hashing technique has drawn much attention nowadays. It takes the binary codes of one modality as the query to retrieve the relevant hashing codes of another modality. However, the existing binary constraint makes it difficult to find the optimal cross-modal hashing function. Most approaches choose to relax the constraint and perform thresholding strategy on the real-value representation instead of directly solving the original objective. In this paper, we first provide a concrete analysis about the effectiveness of multimodal networks in preserving the inter- and intra-modal consistency. Based on the analysis, we provide a so-called  Deep Binary Reconstruction  (DBRC) network that can directly learn the binary hashing codes in an unsupervised fashion. The superiority comes from a proposed simple but efficient activation function, named as  Adaptive Tanh  (ATanh). The ATanh function can adaptively learn the binary codes and be trained via back-propagation. Extensive experiments on three benchmark datasets demonstrate that DBRC outperforms several state-of-the-art methods in both image2text and text2image retrieval task.", "citation": "Not cited", "departments": ["Northwestern Polytechnical University", "Northwestern Polytechnical University", "Northwestern Polytechnical University"], "authors": ["Xuelong Li.....http://dblp.org/pers/hd/l/Li:Xuelong", "Di Hu.....http://dblp.org/pers/hd/h/Hu:Di", "Feiping Nie.....http://dblp.org/pers/hd/n/Nie:Feiping"], "conf": "mm", "year": "2017", "pages": 9}
{"title": "Surrogate Functions for Maximizing Precision at the Top.", "fields": ["uniform convergence", "perceptron", "stochastic gradient descent", "mathematical proof", "cutting plane method"], "abstract": "The problem of maximizing precision at the top of a ranked list, often dubbed Precision@k (prec@k), finds relevance in myriad learning applications such as ranking, multi-label classification, and learning with severe label imbalance. However, despite its popularity, there exist significant gaps in our understanding of this problem and its associated performance measure.\n\nThe most notable of these is the lack of a convex upper bounding surrogate for prec@k. We also lack scalable perceptron and stochastic gradient descent algorithms for optimizing this performance measure. In this paper we make key contributions in these directions. At the heart of our results is a family of truly upper bounding surrogates for prec@k. These surrogates are motivated in a principled manner and enjoy attractive properties such as consistency to prec@k under various natural margin/noise conditions.\n\nThese surrogates are then used to design a class of novel perceptron algorithms for optimizing prec@k with provable mistake bounds. We also devise scalable stochastic gradient descent style methods for this problem with provable convergence bounds. Our proofs rely on novel uniform convergence bounds which require an in-depth analysis of the structural properties of prec@k and its surrogates. We conclude with experimental results comparing our algorithms with state-of-the-art cutting plane and stochastic gradient algorithms for maximizing prec@k.", "citation": "Citations (7)", "year": "2015", "departments": ["Microsoft", "Indian Institute of Science", "Microsoft"], "conf": "icml", "authors": ["Purushottam Kar.....http://dblp.org/pers/hd/k/Kar:Purushottam", "Harikrishna Narasimhan.....http://dblp.org/pers/hd/n/Narasimhan:Harikrishna", "Prateek Jain.....http://dblp.org/pers/hd/j/Jain_0002:Prateek"], "pages": 10}